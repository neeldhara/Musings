{"title":"Sam I Am","markdown":{"yaml":{"title":"Sam I Am","date":"2021-10-01","categories":["cp","lecturenotes"],"fields":["date","title"],"toc":true,"reference-location":"margin"},"headingText":"The Problem","containsRefs":false,"markdown":"\n\n\n\n\nThis is mostly about solving Sam I Am ([UVa 11419](https://onlinejudge.org/external/114/11419.pdf)); en route, we will end up discovering Kőnig's theorem, which is a delightful fact about the special relationship shared by vertex covers and maximum matchings in bipartite graphs.\n\n\nHere's an abridged version of the problem statement.\n\n> Sam is facing a temple which can be described by a $m \\times n$ grid and **he has the locations of all enemies in the temple** (each location can be thought of as the intersection of a row and a column in this grid).\n\nAll of a sudden, he realizes that he can kill the enemies without entering the temple using the great cannon ball which spits out a gigantic ball bigger than him killing anything it runs into and keeps on rolling until it finally explodes.\n\n**But the cannonball can only shoot horizontally or vertically and all the enemies along the path of that cannon ball will be killed.**\n\nSam wants to know the **minimum number of cannon balls** and the positions from which he can shoot the cannonballs **to eliminate all enemies** from outside that temple.\n>\n\n## Some initial observations with an example\n\nSo to begin with, we have a grid with some cells identified as locations where Sam's enemies are positioned, and here's an example:\n\n![A first example of a configuration of Sam's enemies location](CP-Week09-Mod03.003.jpeg)\n\n[Conveniently for us, the enemies don't move around.]{.aside}\n\nWe want to *hit* all of these locations, and what we have at our disposal is giant cannon balls which can destroy all enemies that are positioned on a single row, or a single column. For example, if we were obsessed about only firing along rows, we would need four cannon balls to tackle 'em all, like so:\n\n![A solution were we fire along rows alone](CP-Week09-Mod03.006.jpeg)\n\nIf Sam was superstitious about shooting along columns only, then he would again need four of these cannon balls to take care of everything:\n\n![A solution were we fire along columns alone](CP-Week09-Mod03.007.jpeg)\n\nHowever, our friend Sam is smart, not superstitious! And if there is anything that he is obsessed about, it is ruthlessly optimal destruction! In other words, he wants to fix everything up, but while using the smallest number of cannon balls possible... and if that means mixing up ranks and files, so be it — notice that you can manage with just three once you combine the use of both axes:\n\n![A solution leveraging a combination of rows and columns](CP-Week09-Mod03.008.jpeg)\n\nAnd for this example in particular, notice that three cannon balls are *necessary*, because we have at least three enemies positioned at locations that share *neither a row nor a column*, implying that no row-fire or column-fire can handle more than one of these locations at once:\n\n![Demonstrating that three canonballs are in fact necessary](CP-Week09-Mod03.009.jpeg)\n\nSo for this example, we know that:\n\n- three cannon balls are necessary &\n- three cannon balls are sufficient.\n\nIn general, let's say that two enemy positions are *mutually independent* if they are on different columns *and* on different rows. Let $k$ be the size of a largest collection of mutually independent positions. Then it is clear that:\n\n- $k$ cannon balls are necessary to handle all enemy locations;\n\nbecause any $\\ell$ fires that handle *all* enemy locations must in particular handle these $k$ mutually independent ones, and each individual fire can get to (at best) one of them — by definition of what it means for two positions to be mutually independent. So if we have a valid solution involving $\\ell$ cannon balls, then $\\ell \\geq k$.\n\nWhat is a less obvious, but considerably fascinating, is the fact that:\n\n- there is always a strategy to hit *all* locations using just $k$ cannon balls. 🤯\n\nA striking situation, no pun intended — the obvious estimate of what is needed turns out to be enough as well! The easy lower bound has a matching upper bound ❤️\n\n## An auxiliary graph\n\nAlright, I think that's enough with the advertising.\n\nHow does this work?\n\nLet's construct the following graph $G = (V,E)$ associated with the grid and the information about enemy positions:\n\n- Introduce a vertex for every row in the grid; say $r_i$ for $1 \\leq i \\leq m$. These are the *row vertices.*\n- Introduce a vertex for every column in the grid; say $c_j$ for $1 \\leq j \\leq n$. These are the *column vertices.*\n\n![The vertices of the auxiliary graph](CP-Week09-Mod03.011.jpeg)\n\n- Introduce the edge $(r_i,c_j)$, $1 \\leq i \\leq n; 1 \\leq j \\leq m$ if and only if the location at the intersection of the $i^{th}$ row and the $j^{th}$ column corresponds to an enemy position.\n\n![The edges of the auxiliary graph](CP-Week09-Mod03.027.jpeg)\n\n![A bipartite graph!](CP-Week09-Mod03.028.jpeg)\n\nObserve that:\n\n- Any matching in $G$ (a collection of mutually disjoint edges) corresponds to a collection of mutually independent enemy positions back in the grid.\n- What we are looking for is a smallest-sized subset $S$ of $V(G)$ such that every edge $e$ in $G$ has at least one of its endpoints in $S$. Such a subset is called a vertex cover.\n\n![A vertex cover](CP-Week09-Mod03.030.jpeg)\n\nSo our claim in the language of grids now translates to:\n\n\n> 📝 The size of a maximum matching in $G$ is equal to the size of a minimum vertex cover in $G$.\n\nin the language of graphs. Keep in mind that as graphs go $G$, happens to be a bipartite graph; which is to say that its vertex set can be parittioned into two parts† such that every edge has exactly one endpoint in each part.\n\n[† In this example, these parts correspond to subsets of row vertices and column vertices.]{.aside}\n\n## Bring in the flows\n\nIs this much ado for nothing? We seem to have done some translation work, but there's no proof of this bold claim in sight just yet... 😬\n\nFair. So here's a roadmap for what we plan to do next:\n\n- Use the graph $G$ as the basis of a flow network.\n- Recall the maxflow-mincut duality.\n- ~~Profit.~~ Show the duality that we are interested in by hooking it up the known one.\n\nSo first things first: we are going to setup a flow network around the graph $G$, and here's a partial picture of what it looks like:\n\n![The flow graph](CP-Week09-Mod03.032.jpeg)\n\nHere's the official description of how we build this up:\n\n- Start with the graph $G$, and orient every edge between a row vertex and a column vertex so that every such edge originates *from* the row vertex and latches on *to* the column vertex.\n- We assign infinite capacities to all the edges in $G$. Go unlimited on the originals! We will even dub these edges *original edges* going forward.\n- Add a source vertex $s$ and add unit-capacity edges $(s,r)$ for every row vertex $r$. We will call these edges the *row selectors.*\n- Add a target vertex $t$ and add unit-capacity edges $(c,t)$ for every column vertex $c$. We will refer to these edges as *column selectors.*\n\nThat's it, that's the flow network $(\\tilde{G},\\kappa)$ based on $G$, where I'm using $\\kappa$ to denote the capacity function. Now let's stare at any valid integral flow in this network — what does it pull out from the middle? 🤔\n\n![A matching hiding in plain sight](CP-Week09-Mod03.035.jpeg)\n\nLet's make the following quick observations in the context of a valid integral flow $f$ in $(\\tilde{G},\\kappa)$:\n\n- The flow on any edge $e$ from $G$ (i.e, an original edge) is either zero or one. Indeed, if $f(e) > 1$, then we violate conservation constraints at both endpoints of $e$.\n- For any row or column vertex, at most one original edge incident to it is used by the flow $f$. In other words, $f(e) = 0$ for all but at most one original edge incident to any row or column vertex. Again, if not, combined with the fact that $f$ is integral and that the row and column selectors have unit capacity, we will violate conservation constraints on the vertex under consideration.\n\nBased on these observations, we have that the set of original edges for which $f(e) = 1$ forms a matching in back in $G$, and in particular, if $f$ was maximum flow, then this set would correspond to a maximum-sized matching. Now, let's look at the corresponding mincut by building the residual graph:\n\n![Edges in the residual graph that have a residual capacity of zero are not shown. Also, the original edges that were used by $f$ have infinite residual capacity but their corresponding back-edges have unit capacity, but this distinction is not emphasised in the picture because it's not particularly relevant to our discussion.](CP-Week09-Mod03.040.jpeg)\n\nEdges in the residual graph that have a residual capacity of zero are not shown. Also, the original edges that were used by $f$ have infinite residual capacity but their corresponding back-edges have unit capacity, but this distinction is not emphasised in the picture because it's not particularly relevant to our discussion.\n\nand considering what vertices are reachable from $s$:\n\n![The vertices reachable from $s$ are marked green, while all remaining vertices are marked red.](CP-Week09-Mod03.042.jpeg)\n\nThe vertices reachable from $s$ are marked green, while all remaining vertices are marked red.\n\nIn the residual graph, I would like to draw your attention to:\n\n- row vertices that are unreachable from $s$,\n- column vertices from where it is impossible to reach $t$.\n\nWe will refer to these vertices as the *misfits —* they are highlighted for you in the picture below:\n\n![The misfits](CP-Week09-Mod03.044.jpeg)\n\nNow roll up your sleeves for some magic. Let's pull up the cut — which we know is in fact a mincut — obtained by considering the set of vertices reachable from $s$ the residual graph corresponding to the maxflow $f$. In pictures, note how we have attracted some column vertices to the $s$-side, and pushed away some row vertices to the $t$-side:\n\n![Some reorganization](CP-Week09-Mod03.046.jpeg)\n\nNote that this is a minimum cut, that is to say, the total capacity of the edges crossing the cut is as small as possible — which means that, in particular, the total capacity is at least (or should that be at most?) finite, and that implies, even more particularly, that *none*[^1] of the original edges cross this cut.\n\n[^1]: Remember how their capacities were infinite? So they just cannot afford to cross a minimum-capacity cut.\n\nSo every original edge is confined to the $s$-camp or the $t$-camp; but note that every original edge is an edge between a row vertex and a column vertex; so if you put two and two together, you see that, in fact, *every edge must be incident to a misfit vertex.* This means that the misfits are what we were looking for all along — they form a vertex cover of $G$!\n\nSo at least we have *some* solution. Is this the best we can hope for?\n\nWhy yes!\n\nNote that every misfit vertex contributes *exactly one unit-capacity edge* to the minimum cut: the misfits on the $s$-side are incident to column selectors, and these edges connect with $t$ on the other side; while misfits on the $t$-side are incident to row selectors, and these edges connect with $s$, which is again on the opposite end. So every misfit vertex contributes exactly one edge to the minimum cut — and there are no other edges that cross the cut, so we have the following sequence of equalities:\n\n- size of the proposed solution = #misfits\n- #misfits = capacity of the minimum cut\n- capacity of the minimum cut = value of the maximum flow\n- value of the maximum flow = size of a maximum matching back in $G$\n- size of a maximum matching back in $G$ = lower bound on our solution\n\nTherefore, we have proposed a solution whose cost matches a lower bound on it, making it optimal! With a slight adjustment of language (dropping misfits in favor of vertex cover), the sequence of inequalities above also shows that the size of a minimum vertex cover in a bipartite graph equals the size of a maximum matching in the graph.\n\nThis was the relationship I'd promised to cover when we started, and it goes by Kőnig's theorem in case you'd like to find out more — the argument we came up with here isn't perhaps the traditional proof, and this is a fact that can be established in several different ways, all fun in their own way ❤️"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"include-after-body":["../../../footer.html"],"toc":true,"reference-location":"margin","output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"0.9.363","theme":"../../../theme.scss","title-block-banner":true,"title":"Sam I Am","date":"2021-10-01","categories":["cp","lecturenotes"],"fields":["date","title"]},"extensions":{"book":{"multiFile":true}}}}}